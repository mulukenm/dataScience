{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing Application\n",
    "\n",
    "This notebook is intended to analyze the similarities and differences of 2020 special reports by NCSES. The analysis my lead to avoid duplication and create collaboration.  This notebook goes through a necessary step of any data science project - data cleaning. Data cleaning is a time consuming and unenjoyable task, yet it's a very important one. Keep in mind, \"garbage in, garbage out\". Feeding data that is not processed properly into a model will give us results that are meaningless.\n",
    "\n",
    "##  1) Data Pre-processing\n",
    "\n",
    "1.1. Getting the data - Scraping data from NCSES website \n",
    "\n",
    "1.2. Cleaning the data - Apply text preprocessing techniques\n",
    "\n",
    "1.3. Organizing the data - Organize the cleaned data into a way that is easy to input into other algorithms\n",
    "\n",
    "The output of this stage  will be clean, organized data in two standard text formats:\n",
    "\n",
    "1. **Corpus** - a collection of text\n",
    "2. **Document-Term Matrix** - word counts in matrix format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Web scraping, pickle imports\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pickle\n",
    "\n",
    "# Scrapes transcript data from https://www.nsf.gov/statistics/publication-index.cfm\n",
    "def url_to_transcript(url):\n",
    "    '''Returns transcript data specifically from https://www.nsf.gov/statistics/publication-index.cfm.'''\n",
    "    page = requests.get(url).text\n",
    "    soup = BeautifulSoup(page, \"lxml\")\n",
    "    text = [p.text for p in soup.find().find_all('p')]\n",
    "    print(url)\n",
    "    return text\n",
    "\n",
    "# URLs of executive summaries of special reports\n",
    "urls = ['https://ncses.nsf.gov/pubs/nsb20201/executive-summary/',\n",
    "        'https://ncses.nsf.gov/pubs/nsb20202/executive-summary/',\n",
    "        'https://ncses.nsf.gov/pubs/nsb20203/executive-summary/',\n",
    "        'https://ncses.nsf.gov/pubs/nsb20204/executive-summary/',\n",
    "        'https://ncses.nsf.gov/pubs/nsb20205/executive-summary/',\n",
    "        'https://ncses.nsf.gov/pubs/nsb20206/executive-summary/',\n",
    "        'https://ncses.nsf.gov/pubs/nsb20207/executive-summary/']\n",
    "\n",
    "# CSpecial reports  names\n",
    "SR = ['NSB-2020-1', 'NSB-2020-2', 'NSB-2020-3', 'NSB-2020-4', 'NSB-2020-5','NSB-2020-6', 'NSB-2020-7']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NSB-2020-1',\n",
       " 'NSB-2020-2',\n",
       " 'NSB-2020-3',\n",
       " 'NSB-2020-4',\n",
       " 'NSB-2020-5',\n",
       " 'NSB-2020-6',\n",
       " 'NSB-2020-7']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.nsf.gov/awardsearch/showAward?AWD_ID=1849735&HistoricalAwards=false',\n",
       " 'https://www.nsf.gov/awardsearch/showAward?AWD_ID=2050833&HistoricalAwards=false']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Web scraping, pickle imports\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pickle\n",
    "\n",
    "# Scrapes transcript data from https://www.nsf.gov/statistics/publication-index.cfm\n",
    "def url_to_transcript(url):\n",
    "    '''Returns transcript data specifically from https://www.nsf.gov/statistics/publication-index.cfm.'''\n",
    "    page = requests.get(url).text\n",
    "    soup = BeautifulSoup(page, \"lxml\")\n",
    "    text = [p.text for p in soup.find().find_all('p')]\n",
    "    print(url)\n",
    "    return text\n",
    "\n",
    "# URLs of executive summaries of special reports\n",
    "urls = ['https://www.nsf.gov/awardsearch/showAward?AWD_ID=1849735&HistoricalAwards=false',\n",
    "        'https://www.nsf.gov/awardsearch/showAward?AWD_ID=2050833&HistoricalAwards=false']\n",
    "\n",
    "# CSpecial reports  names\n",
    "SR = ['NSB-2020-1', 'NSB-2020-2']\n",
    "\n",
    "urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.nsf.gov/awardsearch/showAward?AWD_ID=1849735&HistoricalAwards=false\n",
      "https://www.nsf.gov/awardsearch/showAward?AWD_ID=2050833&HistoricalAwards=false\n"
     ]
    }
   ],
   "source": [
    "# Actually request transcripts (takes a few minutes to run)\n",
    "transcripts = [url_to_transcript(u) for u in urls]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A subdirectory or file transcripts already exists.\n"
     ]
    }
   ],
   "source": [
    "# Pickle files for later use\n",
    "\n",
    "# Make a new directory to hold the text files\n",
    "!mkdir transcripts\n",
    "\n",
    "for i, c in enumerate(SR):\n",
    "    with open(\"transcripts/\" + c + \".txt\", \"wb\") as file:\n",
    "        pickle.dump(transcripts[i], file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pickled files---this helps to use saved files to reduce running\n",
    "data = {}\n",
    "for i, c in enumerate(SR):\n",
    "    with open(\"transcripts/\" + c + \".txt\", \"rb\") as file:\n",
    "        data[c] = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['NSB-2020-1', 'NSB-2020-2'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Double check to make sure data has been loaded properly\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n',\n",
       " \"\\nABSTRACT\\n\\nThis project will advance efforts of the Innovative Technology Experiences for Students and Teachers (ITEST) program by preparing high-achieving high school students for advanced science and math courses and eventually courses in engineering. ITEST seeks to better understand and promote practices that increase students' motivations and capacities to pursue careers in fields of science, technology, engineering, and mathematics (STEM). To be globally competitive, the US must optimize the available workforce to include women in STEM. There are two fundamental issues that need to be addressed in engaging women in engineering: motivation and preparedness to pursue STEM careers. The Academy of Natural Sciences will partner with Drexel University: College of Engineering and School of Education, and local engineering professionals, through the Engineering WINS (EngWINS) program. EngWINS will develop the capabilities of working engineers and faculty to serve as mentors in a new initiative to develop interest, self-efficacy, and persistence in engineering careers among urban high school women. The project's immediate impacts extend from an out-of-school learning environment and into urban academic and industrial research centers. The workforce development would be fueled by: 1) diversifying the STEM pipeline, 2) supporting the advancement of all women in STEM fields, and 3) studying the impacts of EngWINS training among adult mentors. The project findings will have relevance for human resource practices in higher education and industry and will be disseminated among educators in engineering in both academic and out of school settings. Project research will investigate how and to what extent a largely homogeneous group of working engineers can enter mentoring relationships that increase participation in their field by underrepresented populations. The project goals, scope, methods, and approaches will address the following questions: To what extent does training in culturally responsive pedagogies and anti-discriminatory frameworks shift adult mentors, mindsets, and dispositions toward their work with EngWINS students, as well as in other teaching contexts or workplace interactions with women and minorities?  To what extent do pairings of mentors and mentees from different backgrounds influence students' interest, self-efficacy, and persistence in engineering education and careers? To what extent does interest, self-efficacy, and persistence in engineering differ between EngWINS students who have a mentor versus. those who only experience the regular EngWINS curriculum?  The projects will use mixed-methods and quasi-experimental design. There will be multiple data sources such as classroom observations, interviews, and surveys/assessments to measure student and mentor outcomes. The project will enroll adult mentor candidates into a full year of professional development training in culturally relevant pedagogies, ways to combat stereotype barriers, and implicit biases, prior to entering mentoring relationships.This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.\\n\"]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# More checks\n",
    "data['NSB-2020-1'][:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries for analysis\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "from gensim import matutils, models\n",
    "import scipy.sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the document-term matrix\n",
    "data = pd.read_pickle('../../Users/muluken/WorkingFiles/GitHUB_Notebooks/NLTK/nlp-in-python-tutorial/dtm_stop.pkl')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One of the required inputs is a term-document matrix\n",
    "tdm = data.transpose()\n",
    "tdm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We're going to put the term-document matrix into a new gensim format, from df --> sparse matrix --> gensim corpus\n",
    "sparse_counts = scipy.sparse.csr_matrix(tdm)\n",
    "corpus = matutils.Sparse2Corpus(sparse_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gensim also requires dictionary of the all terms and their respective location in the term-document matrix\n",
    "cv = pickle.load(open(\"../../Users/muluken/WorkingFiles/GitHUB_Notebooks/NLTK/nlp-in-python-tutorial/cv_stop.pkl\", \"rb\"))\n",
    "#id2word = dict((v, k) for k, v in cv.vocabulary_.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
