{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de55dd04",
   "metadata": {},
   "source": [
    "# Web Scrapping\n",
    "\n",
    "Web scrapping is used to extract data from publicly available websites in automated fashion. The method is useful when the public website you want to get data from does not have an API, or it does but provides only limited access to the data. urllib and requests are Python modules used for web requests in web scraping."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85184b1",
   "metadata": {},
   "source": [
    "* Urllib package is the URL handling module for python. It is used to fetch URLs (Uniform Resource Locators).\n",
    "* Beautiful Soup is a library that makes it easy to scrape information from web pages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0207ca68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from urllib.error import HTTPError\n",
    "from urllib.error import URLError\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "html = urlopen('https://www.ncses.nsf.gov/about')\n",
    "print(html.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da257391",
   "metadata": {},
   "outputs": [],
   "source": [
    "html = urlopen('https://www.ncses.nsf.gov/about')\n",
    "bs = BeautifulSoup(html.read(), 'html.parser')\n",
    "print(bs.h1)\n",
    "print(bs.h2)\n",
    "print(bs.h3)\n",
    "print(bs.find_all([\"h1\", \"h2\"]));\n",
    "# print(bs.find_all([\"h1\", \"h2\", \"h3\", \"h4\", \"h5\", \"h6\"]));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b71213b",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    html = urlopen(\"https://www.ncses.nsf.gov/about\")\n",
    "except HTTPError as e:\n",
    "    print(\"The server returned an HTTP error\")\n",
    "except URLError as e:\n",
    "    print(\"The server could not be found!\")\n",
    "else:\n",
    "    print(html.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca037a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "resp = requests.get('https://www.ncses.nsf.gov/about')\n",
    "print(resp.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d317fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "html = urlopen('http://www.pythonscraping.com/pages/warandpeace.html')\n",
    "bs = BeautifulSoup(html, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dad5883",
   "metadata": {},
   "outputs": [],
   "source": [
    "nameList = bs.findAll('span', {'class': 'green'})\n",
    "for name in nameList:\n",
    "    print(name.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b828df02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b25abe5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
